{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GdhHDgrwkszz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ***Python program to create Image Classifier using CNN ***"
      ]
    },
    {
      "metadata": {
        "id": "OMyRbrEahRW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing the required libraries \n",
        "import cv2 \n",
        "import os \n",
        "import numpy as np \n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEr1hsf8hdHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ckkRxg0rkl--",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Getting the values from pickle file as numpy arrays"
      ]
    },
    {
      "metadata": {
        "id": "KyG6L1zlQPao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reading the data from pickle file to see the input image was a challenge. It was necessary as I wanted to process images as grayscale. The images first appeared as black then after some changes showed up in grayscale"
      ]
    },
    {
      "metadata": {
        "id": "SdB4g3p3hjY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open('C:/Users/MEDHA/Desktop/midas_iiitd/train_image.pkl', 'rb')\n",
        "f = open('C:/Users/MEDHA/Desktop/midas_iiitd/train_label.pkl', 'rb')\n",
        "f1=open('C:/Users/MEDHA/Desktop/midas_iiitd/test_image.pkl', 'rb')\n",
        "image = pickle.load(file)\n",
        "xx = np.array(image)\n",
        "im=pickle.load(f)\n",
        "a=np.array(im)\n",
        "im1 = pickle.load(f1)\n",
        "b=np.array(im1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7T1uACrUkfd-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting up the env"
      ]
    },
    {
      "metadata": {
        "id": "Jv0b8cdGQntH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing of the data was a bit tricky as the training data and the label had to be called upon together and related. While thinking upon I discovered two methods to do the same. One was directly calling the training data and the corresponding label. Second one was creating a matrix of labels and training data with the corresponding label having value 1 and all others having value 0. I went with the first approach as I tried it first didn't get any probable errors."
      ]
    },
    {
      "metadata": {
        "id": "lKRW8EWQhmP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#setting up the learning rate\n",
        "LR = 1e-3\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ek0P7A4mkbXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Labelling the dataset\n",
        "\n",
        "Label Dataset was parsed from the pickle file and the function is made so that we can call the data easil. It returns the label at the specified position m"
      ]
    },
    {
      "metadata": {
        "id": "tfbvDaZjhrea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def label_img(m): \n",
        "    s=a[m]\n",
        "    return s\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wFsOwTykVfg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating the training data\n",
        "\n",
        "Creating training data was easily done as we called the data unpackd from the pickle fil and appended it into a list with the label data"
      ]
    },
    {
      "metadata": {
        "id": "bhXk2Z9dht06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_train_data(): \n",
        "    # Creating an empty list where we should the store the training data \n",
        "    # after a little preprocessing of the data \n",
        "    training_data = [] \n",
        "    q=0\n",
        "\n",
        "    # loading the training data \n",
        "    for img in xx: \n",
        "        \n",
        "        # labeling the images \n",
        "        label = label_img(q) \n",
        "  \n",
        "        training_data.append([np.array(img), np.array(label)])\n",
        "        \n",
        "        q=q+1\n",
        "  \n",
        "    # saving our trained data for further uses if required \n",
        "    np.save('train_data.npy', training_data) \n",
        "    return training_data \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R210QQJVkRLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Processing the given test data\n",
        "\n",
        "Processing of test data was simple and directly the pickle file unpacked was called serially\n"
      ]
    },
    {
      "metadata": {
        "id": "N5kbPyDOhzwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_test_data(): \n",
        "    testing_data = [] \n",
        "    j=0\n",
        "    for img in b: \n",
        "        testing_data.append([np.array(img), j]) \n",
        "        j=j+1\n",
        "    \n",
        "    np.save('test_data.npy', testing_data) \n",
        "    return testing_data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrY342RKkFYP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Running the training and the testing in the dataset for our model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DvmwGS6Sh7kM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = create_train_data() \n",
        "test_data = process_test_data() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpcZT4izkBl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating the neural network using tensorflow\n",
        "\n",
        "Faced a lot of challenges while traing the model as dimensions of the label wasn't compatible with that of the input given.\n",
        "\n",
        "Also for fully connected layer softmax activation function wasn't working so had to switch over to linear activation function\n"
      ]
    },
    {
      "metadata": {
        "id": "8ipzyo0ih_P2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the required libraries \n",
        "import tflearn \n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
        "from tflearn.layers.core import input_data, dropout, fully_connected \n",
        "from tflearn.layers.estimator import regression \n",
        "  \n",
        "import tensorflow as tf \n",
        "IMG_SIZE=28\n",
        "tf.reset_default_graph() \n",
        "convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input') \n",
        "  \n",
        "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
        "convnet = max_pool_2d(convnet, 5) \n",
        "  \n",
        "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
        "convnet = max_pool_2d(convnet, 5) \n",
        "  \n",
        "convnet = conv_2d(convnet, 128, 5, activation ='relu') \n",
        "convnet = max_pool_2d(convnet, 5) \n",
        "  \n",
        "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
        "convnet = max_pool_2d(convnet, 5) \n",
        "  \n",
        "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
        "convnet = max_pool_2d(convnet, 5) \n",
        "  \n",
        "convnet = fully_connected(convnet, 1024, activation ='relu') \n",
        "convnet = dropout(convnet, 0.8) \n",
        "  \n",
        "convnet = fully_connected(convnet, 1, activation='linear') \n",
        "convnet = regression(convnet, optimizer ='adam', learning_rate = LR, \n",
        "      loss ='categorical_crossentropy', name ='targets') \n",
        "  \n",
        "model = tflearn.DNN(convnet, tensorboard_dir ='log') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ZTEcYTaj-NM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " \n",
        "###Splitting the testing data and training data \n",
        "\n",
        "Would like to achieve higher accuracy while doing this as the test has only 6 as values and assuming test more than 1000 is giving erroneous values"
      ]
    },
    {
      "metadata": {
        "id": "6qPdvkptiGSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train_data[:-500] \n",
        "test = train_data[-500:] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJHS3WQSj5ch",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting up the features and lables\n",
        "\n",
        "\n",
        "Scaling the labels aptly was a challenge"
      ]
    },
    {
      "metadata": {
        "id": "VeyCf0TXiIs1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# X-Features & Y-Labels \n",
        "  \n",
        "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "Y = np.array([i[1] for i in train]).reshape(-1, 1) \n",
        "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "test_y = np.array([i[1] for i in test]).reshape(-1, 1)  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HI9glPEXjqJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Fitting the data into our model\n",
        "\n",
        "5 Epochs"
      ]
    },
    {
      "metadata": {
        "id": "PRD9US8iiNrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# epoch = 5 taken \n",
        "model.fit({'input': X}, {'targets': Y}, n_epoch = 5, \n",
        "    validation_set =({'input': test_x}, {'targets': test_y}),\n",
        "    snapshot_step = 500, show_metric = True, run_id = None) \n",
        "model.save('new') \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5T78kS2jlqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing the data\n",
        "\n",
        "The final prediction is done by rounding the values to the nearest label possible."
      ]
    },
    {
      "metadata": {
        "id": "hOFBFu2riRO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        " \n",
        "# if you need to create the test data: \n",
        "#test_data = process_test_data() \n",
        "# if you already have some saved: \n",
        "test_data = np.load('test_data.npy') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QEcmBlKjhlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "getting labels for test data"
      ]
    },
    {
      "metadata": {
        "id": "CBQ-sHvViXIX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_results = []\n",
        "for num, data in enumerate(test_data[0:2000]):\n",
        "\n",
        "      \n",
        "    img_num = data[1] \n",
        "    img_data = data[0] \n",
        "      \n",
        "   \n",
        "    orig = img_data \n",
        "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1) \n",
        "  \n",
        "   \n",
        "    model_out = model.predict([data])[0] \n",
        "\n",
        "    if(model_out[0]>4.5):\n",
        "        predicted_results.append(6)\n",
        "    elif(model_out[0]>2.5):\n",
        "        predicted_results.append(3)\n",
        "    elif(model_out[0]>1.5):\n",
        "        predicted_results.append(2)\n",
        "    elif(model_out[0]>0):\n",
        "        predicted_results.append(0)\n",
        "        \n",
        "print(predicted_results)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1pV9mbo1ig7S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Writing the output to csv file"
      ]
    },
    {
      "metadata": {
        "id": "j39DdoCKidyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "with open('Medha_Mani_fin.csv','w') as myoutputfile:\n",
        "    myoutputfile.write('Test_image_index, predicted class \\n')\n",
        "    for i in range(0,2000):\n",
        "        myoutputfile.write(str(i)+','+str(predicted_results[i])+'\\n')\n",
        "    myoutputfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wyTureuKUZ7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Further improvements: The csv file I created wasn't giving 6 as output label due to some discripencies that was there while rounding off the values. These things have been improved in the latest commit***"
      ]
    }
  ]
}